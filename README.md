# ğŸ¢ Data Warehouse AdventureWorks - Projeto AcadÃªmico

## ğŸ“– DescriÃ§Ã£o
Projeto acadÃªmico de construÃ§Ã£o de um Data Warehouse completo com processos ETL automatizados utilizando Apache Airflow. Baseado no banco de dados AdventureWorks (empresa fictÃ­cia de venda de bicicletas), este projeto implementa um modelo dimensional (esquema estrela) para anÃ¡lise de vendas.

## ğŸ¯ Objetivo
Construir um Data Warehouse funcional que permita anÃ¡lise de dados de vendas atravÃ©s de 10 indicadores-chave (KPIs), demonstrando:
- Modelagem dimensional
- Processos ETL automatizados
- CÃ¡lculo de mÃ©tricas de negÃ³cio
- Boas prÃ¡ticas de engenharia de dados

## ğŸ› ï¸ Tecnologias Utilizadas
- **PostgreSQL 15** - Banco de dados relacional
- **Apache Airflow 2.7.3** - OrquestraÃ§Ã£o de workflows ETL
- **Python 3.11** - Linguagem de programaÃ§Ã£o para ETL
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o
- **psycopg2** - Driver Python para PostgreSQL

## ğŸ—ï¸ Arquitetura do Projeto

### Bancos de Dados
1. **postgres-source (porta 5435)** - Banco fonte com dados originais do AdventureWorks
2. **postgres-dw (porta 5434)** - Data Warehouse com modelo dimensional
3. **postgres-airflow (porta 5433)** - Metadados do Airflow

### Modelo Dimensional (Esquema Estrela)

**DimensÃµes:**
- ğŸ—“ï¸ `dim_tempo` - DimensÃ£o temporal (2011-2014)
- ğŸ“¦ `dim_produto` - Produtos comercializados
- ğŸ‘¤ `dim_cliente` - Clientes (individuais e lojas)
- ğŸŒ `dim_territorio` - RegiÃµes de vendas
- ğŸ‘” `dim_vendedor` - Vendedores
- ğŸšš `dim_metodo_envio` - MÃ©todos de entrega

**Fato:**
- ğŸ’° `fato_vendas` - TransaÃ§Ãµes de vendas com mÃ©tricas

## ğŸ“Š 10 Indicadores (KPIs) Implementados

1. **Total de vendas por regiÃ£o** - Receita e lucro por territÃ³rio
2. **Produtos mais vendidos (Top 20)** - Ranking por quantidade e receita
3. **Ticket mÃ©dio por cliente** - Valor mÃ©dio gasto por cliente
4. **Taxa de crescimento mensal** - VariaÃ§Ã£o percentual mÃªs a mÃªs
5. **Margem de lucro por categoria** - Rentabilidade por categoria de produto
6. **Taxa de conversÃ£o online** - Percentual de pedidos online vs total
7. **Clientes mais valiosos (Top 10)** - Maiores geradores de receita
8. **Desempenho de vendedores** - Performance individual de vendedores
9. **Sazonalidade de vendas** - PadrÃµes ao longo dos meses
10. **Vendas por dia da semana** - AnÃ¡lise de demanda por dia

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Docker instalado
- Docker Compose instalado
- 4GB de RAM disponÃ­vel
- 10GB de espaÃ§o em disco

### 1. Subir o ambiente
```bash
cd /home/marcogalter/olap
docker-compose up -d
```

Aguarde 2-3 minutos para todos os serviÃ§os iniciarem.

### 2. Verificar containers
```bash
docker-compose ps
```

Todos devem estar com status "Up".

### 3. Acessar o Airflow
- **URL:** http://localhost:8080
- **UsuÃ¡rio:** `admin`
- **Senha:** `admin`

### 4. Executar ETL

**Passo 1:** Execute a DAG `etl_dimensions`
- Carrega todas as dimensÃµes
- Tempo estimado: 1-2 minutos

**Passo 2:** Execute a DAG `etl_fact_sales`
- Carrega a tabela fato de vendas
- Tempo estimado: 2-3 minutos
- âš ï¸ **SÃ³ execute apÃ³s a DAG de dimensÃµes ter sucesso!**

### 5. Consultar KPIs
```bash
# Conectar no Data Warehouse
docker exec -it olap_postgres-dw_1 psql -U dw_user -d adventureworks_dw

# Executar queries de KPIs
\i /opt/airflow/sql/03_kpis_queries.sql
```

## ğŸ“ Estrutura do Projeto
```
olap/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ etl_dimensions.py          # DAG: Carga de dimensÃµes
â”‚   â”œâ”€â”€ etl_fact_sales.py          # DAG: Carga da tabela fato
â”‚   â””â”€â”€ etl_utils.py               # FunÃ§Ãµes auxiliares para ETL
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_create_dimensions.sql   # DDL das tabelas dimensionais
â”‚   â”œâ”€â”€ 02_create_fact_table.sql   # DDL da tabela fato e views
â”‚   â””â”€â”€ 03_kpis_queries.sql        # Queries dos 10 KPIs
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ GUIA_EXECUCAO.md          # Guia detalhado de execuÃ§Ã£o
â”‚   â””â”€â”€ DICIONARIO_DADOS.md       # DicionÃ¡rio completo de dados
â”œâ”€â”€ data/
â”‚   â””â”€â”€ adventureworks.sql         # Dump do banco fonte
â”œâ”€â”€ logs/                          # Logs do Airflow
â”œâ”€â”€ plugins/                       # Plugins customizados
â”œâ”€â”€ docker-compose.yml             # OrquestraÃ§Ã£o dos containers
â”œâ”€â”€ .gitignore                     # Arquivos ignorados pelo Git
â””â”€â”€ README.md                      # Este arquivo
```

## ğŸ“ˆ ValidaÃ§Ã£o de Dados

Execute para validar a carga:
```bash
docker exec olap_postgres-dw_1 psql -U dw_user -d adventureworks_dw -c "
SELECT 'dim_tempo' as tabela, COUNT(*) as registros FROM dim_tempo
UNION ALL SELECT 'dim_produto', COUNT(*) FROM dim_produto
UNION ALL SELECT 'dim_cliente', COUNT(*) FROM dim_cliente
UNION ALL SELECT 'dim_territorio', COUNT(*) FROM dim_territorio
UNION ALL SELECT 'dim_vendedor', COUNT(*) FROM dim_vendedor
UNION ALL SELECT 'dim_metodo_envio', COUNT(*) FROM dim_metodo_envio
UNION ALL SELECT 'fato_vendas', COUNT(*) FROM fato_vendas;
"
```

**Valores esperados:**
- dim_tempo: ~1,461 registros
- dim_produto: ~504 registros
- dim_cliente: ~19,820 registros
- dim_territorio: 10 registros
- dim_vendedor: 17 registros
- dim_metodo_envio: 5 registros
- fato_vendas: ~121,317 registros

## ğŸ”§ Troubleshooting

### Containers nÃ£o sobem
```bash
docker-compose down
docker-compose up -d
```

### DAGs nÃ£o aparecem no Airflow
```bash
docker-compose restart airflow-scheduler
```

### Resetar dados do DW
```bash
docker exec olap_postgres-dw_1 psql -U dw_user -d adventureworks_dw -c "
TRUNCATE TABLE fato_vendas CASCADE;
TRUNCATE TABLE dim_tempo CASCADE;
TRUNCATE TABLE dim_produto CASCADE;
TRUNCATE TABLE dim_cliente CASCADE;
TRUNCATE TABLE dim_territorio CASCADE;
TRUNCATE TABLE dim_vendedor CASCADE;
TRUNCATE TABLE dim_metodo_envio CASCADE;
"
```

### Ver logs do Airflow
```bash
docker-compose logs -f airflow-scheduler
docker-compose logs -f airflow-webserver
```

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **[Guia de ExecuÃ§Ã£o Completo](docs/GUIA_EXECUCAO.md)** - InstruÃ§Ãµes detalhadas
- **[DicionÃ¡rio de Dados](docs/DICIONARIO_DADOS.md)** - DescriÃ§Ã£o completa das tabelas

