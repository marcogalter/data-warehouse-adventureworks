# üöÄ Guia de Execu√ß√£o do Projeto

## üìä Modelo Dimensional

### Dimens√µes
1. **dim_tempo** - Dimens√£o temporal (2011-2014)
2. **dim_produto** - Produtos da empresa
3. **dim_cliente** - Clientes (individuais e lojas)
4. **dim_territorio** - Regi√µes de venda
5. **dim_vendedor** - Vendedores da empresa
6. **dim_metodo_envio** - M√©todos de entrega

### Fato
**fato_vendas** - Vendas realizadas com m√©tricas de receita, lucro, quantidade, etc.

---

## üîß Como Executar o ETL

### 1. Acessar o Airflow
```
URL: http://localhost:8080
Usu√°rio: admin
Senha: admin
```

### 2. Executar ETL das Dimens√µes
1. No Airflow, localize a DAG **`etl_dimensions`**
2. Clique no bot√£o de "Play" (‚ñ∂Ô∏è) √† direita
3. Selecione **"Trigger DAG"**
4. Aguarde a execu√ß√£o (leva cerca de 1-2 minutos)
5. Verifique se todas as tarefas ficaram verdes ‚úÖ

**Ordem de execu√ß√£o das tarefas:**
- load_dim_tempo
- load_dim_produto
- load_dim_cliente
- load_dim_territorio
- load_dim_vendedor
- load_dim_metodo_envio

### 3. Executar ETL da Tabela Fato
**‚ö†Ô∏è IMPORTANTE: S√≥ execute ap√≥s a DAG de dimens√µes ter sucesso!**

1. Localize a DAG **`etl_fact_sales`**
2. Clique no bot√£o de "Play" (‚ñ∂Ô∏è)
3. Selecione **"Trigger DAG"**
4. Aguarde a execu√ß√£o (leva cerca de 2-3 minutos)
5. Verifique se as tarefas ficaram verdes ‚úÖ

**Tarefas executadas:**
- load_fato_vendas (carrega dados de vendas)
- validate_fato_vendas (valida a carga)

---

## üìà 10 Indicadores (KPIs) Implementados

### 1. Total de vendas por regi√£o
Receita, lucro e quantidade de pedidos por territ√≥rio de vendas.

### 2. Produtos mais vendidos (Top 20)
Ranking de produtos por quantidade vendida e receita gerada.

### 3. Ticket m√©dio por cliente
Valor m√©dio gasto por cada cliente.

### 4. Taxa de crescimento mensal de vendas
Compara√ß√£o m√™s a m√™s do crescimento de receita (%).

### 5. Margem de lucro por categoria de produto
Rentabilidade de cada categoria de produto.

### 6. Taxa de convers√£o de pedidos online
Percentual de pedidos feitos online vs total.

### 7. Clientes mais valiosos (Top 10)
Clientes que mais geraram receita.

### 8. Desempenho de vendedores
Performance individual de cada vendedor.

### 9. Sazonalidade de vendas
Padr√µes de venda ao longo dos meses do ano.

### 10. An√°lise por dia da semana
Em quais dias h√° mais vendas.

---

## üîç Como Executar os KPIs

### Op√ß√£o 1: Via Terminal
```bash
# Conectar no banco DW
docker exec -it olap_postgres-dw_1 psql -U dw_user -d adventureworks_dw

# Executar qualquer query do arquivo 03_kpis_queries.sql
# Exemplo: Total de vendas por regi√£o
SELECT 
    dter.nome as territorio,
    SUM(fv.valor_liquido) as receita_total
FROM fato_vendas fv
LEFT JOIN dim_territorio dter ON fv.territorio_id = dter.territorio_id
GROUP BY dter.nome
ORDER BY receita_total DESC;
```

### Op√ß√£o 2: Executar arquivo completo
```bash
docker exec -i olap_postgres-dw_1 psql -U dw_user -d adventureworks_dw < sql/03_kpis_queries.sql
```

---

## ‚úÖ Checklist de Valida√ß√£o

Ap√≥s executar as DAGs, valide:

- [ ] Dimens√£o Tempo tem ~1461 registros (4 anos)
- [ ] Dimens√£o Produto tem ~504 produtos
- [ ] Dimens√£o Cliente tem ~19000+ clientes
- [ ] Dimens√£o Territ√≥rio tem 10 territ√≥rios
- [ ] Dimens√£o Vendedor tem 17 vendedores
- [ ] Dimens√£o M√©todo Envio tem 5 m√©todos
- [ ] Fato Vendas tem ~121000+ registros
- [ ] Todas as queries de KPI executam sem erro

### Comandos de Valida√ß√£o R√°pida
```bash
# Ver quantidade de registros em cada tabela
docker exec olap_postgres-dw_1 psql -U dw_user -d adventureworks_dw -c "
SELECT 'dim_tempo' as tabela, COUNT(*) as registros FROM dim_tempo
UNION ALL
SELECT 'dim_produto', COUNT(*) FROM dim_produto
UNION ALL
SELECT 'dim_cliente', COUNT(*) FROM dim_cliente
UNION ALL
SELECT 'dim_territorio', COUNT(*) FROM dim_territorio
UNION ALL
SELECT 'dim_vendedor', COUNT(*) FROM dim_vendedor
UNION ALL
SELECT 'dim_metodo_envio', COUNT(*) FROM dim_metodo_envio
UNION ALL
SELECT 'fato_vendas', COUNT(*) FROM fato_vendas;
"
```

---

## üêõ Troubleshooting

### DAG n√£o aparece no Airflow
```bash
# Reiniciar scheduler
docker-compose restart airflow-scheduler
```

### Erro de conex√£o com banco
```bash
# Verificar se containers est√£o rodando
docker-compose ps

# Ver logs
docker-compose logs postgres-dw
docker-compose logs postgres-source
```

### Limpar dados e reexecutar
```bash
# Truncar todas as tabelas
docker exec olap_postgres-dw_1 psql -U dw_user -d adventureworks_dw -c "
TRUNCATE TABLE fato_vendas CASCADE;
TRUNCATE TABLE dim_tempo CASCADE;
TRUNCATE TABLE dim_produto CASCADE;
TRUNCATE TABLE dim_cliente CASCADE;
TRUNCATE TABLE dim_territorio CASCADE;
TRUNCATE TABLE dim_vendedor CASCADE;
TRUNCATE TABLE dim_metodo_envio CASCADE;
"
```

---

## üìÅ Estrutura de Arquivos

```
olap/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ etl_dimensions.py      # DAG para carregar dimens√µes
‚îÇ   ‚îú‚îÄ‚îÄ etl_fact_sales.py      # DAG para carregar fato
‚îÇ   ‚îî‚îÄ‚îÄ etl_utils.py           # Fun√ß√µes auxiliares
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îú‚îÄ‚îÄ 01_create_dimensions.sql   # DDL das dimens√µes
‚îÇ   ‚îú‚îÄ‚îÄ 02_create_fact_table.sql   # DDL da tabela fato
‚îÇ   ‚îî‚îÄ‚îÄ 03_kpis_queries.sql        # Queries dos 10 KPIs
‚îú‚îÄ‚îÄ docs/                      # Documenta√ß√£o adicional
‚îú‚îÄ‚îÄ data/                      # Dados fonte
‚îú‚îÄ‚îÄ docker-compose.yml         # Configura√ß√£o dos containers
‚îî‚îÄ‚îÄ README.md                  # Este arquivo
```

---

## üìä Para o Artigo Acad√™mico

### Prints Necess√°rios
1. ‚úÖ Diagrama do modelo estrela (pode fazer no draw.io ou lucidchart)
2. ‚úÖ Print das DAGs no Airflow (Graph View)
3. ‚úÖ Print das execu√ß√µes bem-sucedidas (verde)
4. ‚úÖ Print dos resultados de pelo menos 3 KPIs
5. ‚úÖ Estrutura das tabelas (pode usar \d no psql)

### Se√ß√µes do Artigo
**Introdu√ß√£o**
- Contexto do Data Warehouse
- Objetivos do projeto
- Justificativa dos KPIs escolhidos

**Desenvolvimento**
- An√°lise do banco AdventureWorks
- Modelo dimensional proposto (diagrama estrela)
- Dicion√°rio de dados
- Descri√ß√£o do processo ETL
- Implementa√ß√£o no Apache Airflow
- Resultados dos KPIs

**Considera√ß√µes Finais**
- Desafios enfrentados
- Resultados obtidos
- Poss√≠veis melhorias futuras

---

## üîó Links √öteis
- Airflow: http://localhost:8080
- PostgreSQL DW: localhost:5434
- PostgreSQL Source: localhost:5435
- Reposit√≥rio GitHub: [seu-link-aqui]
